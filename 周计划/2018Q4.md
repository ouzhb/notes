# 【项目1】大数据平台

##【子项目】IBNS项目相关任务

### 【三级拆解】Spark集群模式Kubernetes部署，以及spark相关任务支撑保障
#### 【阶段目标】 Spark-Cluster 部署，App任务提交任务方案设计
- [ ] 【D】10月8日，Spark on glusterfs 以及 hadoop on glusterfs调研
    - [ ] 【本日进展】
        - hadoop/spark on glusterfs 插件调研。该插件可以是Hadoop/Spark直接读写数据到glusterfs。git上该插件已经3年没有更新，个人判断目前应该用不上这个插件。
        - Q4任务拆分
        - Spark Standalone jar包分发机制确认。Jar的分发路径为Client -> Driver -> worker。Driver到worker这步是自动完成的，但是Client到Driver这一步需要手工完成（或者将Jar放到HDFS、http服务器）。
- [ ] 【D】10月9日，Standalone模式下，设计Spark任务提交方式、业务jar包分发方式、业务Helm包打包方式。
    - [ ] 【本日进展】
        - 集群模式下的Checkpoint问题：可以确定Checkpoint目录必须是共享目录（HDFS/所有workder可以的目录）。官网没有叙述streaming任务必须配置checkpoint目录，但是博客的说法是DStream的有状态转换需要checkpoint（有状态转换算子包括：updateStatebyKey，window，特点是依赖之前的批次数据或者中间结果来计算当前批次的数据）。WIS业务代码中没有使用updateStatebyKey、window算子。但是Kafka依赖库中有使用到updateStatebyKey。（PS：咨询过玉良，没有给wo答复）
        - 集群模式下的Shuffle异常问题：表现为从本地Shuffle读Block时找不对应的Shuffle文件，但是该问题时有时无需要进一步观察。
~~- [ ] 【D】10月10日，Streaming 任务监控功能开发~~
- [ ] 【D】10月10日，Standalone模式下，设计Spark任务提交方式、业务jar包分发方式、业务Helm包打包方式。输出使用文档
    - [ ] 【本日进展】
        - spark集群模式使用文档，集群模式wis任务helm包修改（文档见附件）-- spark集群模式的helm包已经基本可用
- [ ] 【D】10月11日，任务监控功能整合Standalone镜像，调试测试
- [ ] 【D】10月12日，Spark Metrics指标接入（包括Master、Worker的指标）
- [ ] 【D】10月13日，Spark jar包重复分发问题解决方案设计
#### 【阶段目标】 Spark REST API接口调研
- [ ] 【D】10月15日，Spark 原生REST API调研
- [ ] 【D】10月16日，Spark Livy服务调研
- [ ] 【D】10月17日，Local 模式Rest API临时方案设计
#### 【阶段目标】 Spark-Cluster稳定测试，单节点到三节点扩容方案，其他问题验证
- [ ] 【D】10月18日，单节点到三节点扩容自验证（包括平台扩容，以及业务资源调整）
- [ ] 【D】10月19日，Spark-Cluster稳定测试（测试用例设计、测试）