# 【项目1】大数据平台

##【子项目】IBNS项目相关任务

### 【三级拆解】Spark集群模式Kubernetes部署，以及spark相关任务支撑保障
#### 【阶段目标】 Spark-Cluster 部署，App任务提交任务方案设计
- [ ] 【D】10月8日，Spark on glusterfs 以及 hadoop on glusterfs调研
    - [ ] 【本日进展】
        - hadoop/spark on glusterfs 插件调研。该插件可以是Hadoop/Spark直接读写数据到glusterfs。git上该插件已经3年没有更新，个人判断目前应该用不上这个插件。
        - Q4任务拆分
        - Spark Standalone jar包分发机制确认。Jar的分发路径为Client -> Driver -> worker。Driver到worker这步是自动完成的，但是Client到Driver这一步需要手工完成（或者将Jar放到HDFS、http服务器）。
- [ ] 【D】10月9日，Standalone模式下，设计Spark任务提交方式、业务jar包分发方式、业务Helm包打包方式。
    - [ ] 【本日进展】
        - 集群模式下的Checkpoint问题：可以确定Checkpoint目录必须是共享目录（HDFS/所有workder可以的目录）。官网没有叙述streaming任务必须配置checkpoint目录，但是博客的说法是DStream的有状态转换需要checkpoint（有状态转换算子包括：updateStatebyKey，window，特点是依赖之前的批次数据或者中间结果来计算当前批次的数据）。WIS业务代码中没有使用updateStatebyKey、window算子。但是Kafka依赖库中有使用到updateStatebyKey。（PS：咨询过玉良，没有给wo答复）
        - 集群模式下的Shuffle异常问题：表现为从本地Shuffle读Block时找不对应的Shuffle文件，但是该问题时有时无需要进一步观察。
~~- [ ] 【D】10月10日，Streaming 任务监控功能开发~~
- [ ] 【D】10月10日，Standalone模式下，设计Spark任务提交方式、业务jar包分发方式、业务Helm包打包方式。输出使用文档
    - [ ] 【本日进展】
        - spark集群模式使用文档，集群模式wis任务helm包修改（文档见附件）-- spark集群模式的helm包已经基本可用
- [ ] 【D】10月11日，任务监控功能整合Standalone镜像，调试测试
    - [ ] 【本日进展】
        - spark 流处理监控功能整合，实现python脚本从streaming页面抓取batches运行时间，通过k8s的健康检查判断是否需要重启流处理任务--- 脚本编码完成，自测试OK
- [ ] 【D】10月12日，spark2 集群环境整合python3，提供给行雄进程调试
    - [ ] 【本日进展】
        - 同步Spark2-Cluster给行雄使用，（工作包括：python3整合、helm包修改、文档修订、Spark Metrics指标接入）  ---- 完成
#### 【阶段目标】 Spark REST API接口调研
- [ ] 【D】10月15日，Spark jobservice 基本功能调研，以及安装使用
    - [ ] 【本日进展】
        - spark jobservice安装部署，使用文档简要整理。基本使用方式，接口功能已经摸清 --- 详情见附件
        - 考虑到jobservice功能比较全面，如果并发性的考量的话自研框架会有局限。所以计划任然以jobservice作为第一选择。
- [ ] ~~【D】10月16日，Spark jobservice 容器化方案确定~~ 【D】10月16日，jobservice开发接口熟悉，编写一个demo查询db，返回查询结果
    - [ ] 【本日进展】
        - 完成jobservice 两个demo编写，包括：一个字符统计，和mongodb查询
        - 和晓林安装拷机环境
- [ ] 【D】10月17日，Spark jobservice 容器化方案确定
    - [ ] 【本日进展】
        - 完成Spark jobservice容器化，输出Helm包。
        - 当前识别到JobService对共享存储有需要。JobService中的一些数据时存储存在文件中的，没有共享存储时pod退出后，需要重新上传jar包。
- [ ] 【D】10月18日，Spark jobservice使用文档，Demo整理
    - [ ] 【本日进展】
        - 完成Job Serverice 的使用说明文档（包括Helm、Demo、文档，已经可以交付使用）
- [ ] 【D】10月19日，~~实现一个spark driver内部的接口，使用户可以动态触发job~~ Spark 集群模式拷机环境部署
    - [ ] 【本日进展】
        - 部署spark cluster到拷机环境，配置wis集群版本，进行拷机（1000倍压力，提高spark任务资源后运行业务正常，但是磁盘io 100%）
        - 搭建glusterfs到拷机环境（输出一个一键部署脚本）
#### 【阶段目标】 Spark-Cluster稳定测试、glusterfs与HDFS选型对比
- [ ] 【D】10月22日，Spark-Cluster 稳定测试，协助AI任务性能问题定位
    - [ ]【本日进展】
        - Spark AI性能问题分析：编码测试DF、RDD读取MongoDB的性能，发现主要性能瓶颈不是mongodb，无论DF还是RDD 500w记录加载完成大概40s
        - Spark AI性能问题分析：翻译AI业务的Python为Scala，发现同样逻辑，scala的性能是python的2倍。
- [ ] 【D】10月23日，glusterfs特性熟悉，与HDFS进行比较（输出比较文档）
    - [ ]【本日进展】
        - IBNS共享存储需求场景分析，共享存储系统调研（当前IBNS的主要需求是：大量的小文件的读写，对可靠性、性能要求不高。但是比较遗憾的是包括：Ceph、Gluster、MooseFS内的分布文件系统，处理小文件性能不佳是通病！而HDFS本身是为高吞吐IO设计的，小文件处理能力是最差的！！ PS：个人认为WIS、IData业务都有在HDFS存储大量小文件的场景，这是一种设计缺陷，可以进行优化）
        - 应ION要求修改Spark基础镜像，安装GCC和指定的库
- [ ] 【D】10月24日，~~glusterfs 和 HDFS 环境下，Spark性能测试对比~~ glusterfs 架构特性调研
    - [ ] 【本日进展】
        - 整合History到Spark2的Helm包（日志目录使用Glusterfs存储）
        - 了解Gluterfs的Volume特性，查找关于Glusterfs底层架构FUSE的资料（PS：从Glusterfs的实现架构来看，该文件系统天生小文件处理能力不佳。创建过多的小文件，会使Glusterfs的性能相比裸盘下降80%之多。 附件文档中有详细说明）
- [ ] 【D】10月25日， glusterfs IO逻辑机梳理，HDFS和Glusterfs相关特性对比
    - [ ] 【本日进展】
        - glusterfs Translator逻辑梳理
        - 输出glusterfs与HDFS比较文档
- [ ] 【D】10月26日， IBNS问题支持，glusterfs HDFS对比，机房搬迁
    - [ ] 【本日进展】
        - 机房搬迁~~~！！！
        - IBNS spark任务问题定位，加载so库失败，原因是缺少环境变量LD_LIBRARY_PATH
        - HDFS Glusterfs 打分表（见附件）


- [ ] 【W】10月31日前，完成hdfs组件容器化实现方案及路径探索，并实现初步原形。

      - [ ] 【D】10月29日，~~hdfs组件容器化实现方案及路径探索(50%)~~ 机房服务器上线，k8s平台环境重装
        - [ ] 【本日进展】
                -  机房服务器上线，k8s平台环境重装
      - [ ] 【D】10月30日, hdfs组件容器化实现方案及路径探索(50%)
        - [ ] 【本日进展】
                - 调研HADOOP容器化方案，输出单节点/多节点初步方案（见附件）
      - [ ] 【D】11月01日，hdfs组件容器化实现方案及路径探索，初步列出可行的方案。
        - [ ] 【本日进展】
                - 排查IBNS任务问题 （具体见附件）
                - 调研 HADOOP 容器的HA方案，发现容器化实施时，存在以下难点：1、初次部署时，Namenode、Journalnode、ZKFC需要顺序执行初始化操作，需要额外开发脚本实现自动初始化；2、Namenode进行主备切换时，需要额外脚本防止脑裂；
                - 完成单节点的Hadoop版本。
      - [ ] 【D】11月02日，待定
      - [ ] 【D】11月03日，待定

- [ ] 【W】11月23日前，总结平台组件选型、故障管理等方面的工作内容，调研能够优化这方面工作的开源组件
        - [ ] 【D】11月19日，总结平台组件选型的一般流程
                - [ ] 【本日进展】调研分布式链路监控工具
                - [ ] 【本日进展】总结选型工作，细化该工作流程。
        - [ ] 【D】11月20日，调研查找能够帮助选型的开源工具
                - [ ] 【本日进展】完成大数据平台价值调研，进行阶段汇报
### 【三级拆解】大数据技术组件容器化方向和价值调研（林清）

调研目标：
-     调研大数据生态中组件的容器化进展，给出组件容器化统计列表和分析的结论/洞见。
-     调研互联网公司的容器应用案例，分析各大公司的容器化发展到何总程度。
-     结合业务需要分别选取存储、计算、采集等领域的组件，深入分析容器方案。构想一个容器化的大数据平台。
-     结合业界动向及公司内部业务，分析上述平台是否能够满足需要，能够带来何种优势。
-     调研成果每周一汇报，以ppt讲解的形式进行。

-     [ ] 【M】11月30日前，完成大数据技术组件容器化的现状分析和价值探索，并输出分析结论。

      - [ ] 【W】11月02日前，调研大数据生态中组件的容器化进展，给出组件容器化统计列表和分析的结论/洞见。
            - [ ] 【D】11月01日前，罗列大数据生态中的常用组件，调研组件是否有官方容器化方案。
                - [ ] 【本日进展】从官方镜像、非官方镜像、HelmChart三个维度整理大数据组件的容器化进程，输出文档。
            - [ ] 【D】11月02日前，分析组件的容器化进程，结合统计结果，输出相关分析/简介
                - [ ] 【本日进展】整理分析组件容器化进度，输出分析文档（从收集到的情况上来看，平台有云化的趋势。下周针对这一点展开进行调研）。
      - [ ] 【W】11月09日前，调研互联网公司公司的容器应用案例，分析大数据平台是否存在云化趋势。
            - [ ] 【D】11月05日前，调研Ali等互联网公司容器化使用场景、案例。
                - [ ] 【本日进展】查找、阅读Ali关于大数据平台、Docker化等内容的技术分享，输出文档（见附件）
            - [ ] 【D】11月06日前，调研Ali等互联网公司容器化使用场景、案例。
                - [ ] 【本日进展】整理2016/2017年Ali双11技术相关分享输出统计表格。（见附件）
            - [ ] ~~【D】11月07日前，调研大数据容器化创业公司SequenceIQ。~~
            - [ ] 【D】11月07日前，整理平台相关工作内容，分析可以推进的方向
                - [ ] 【本日进展】整理平台相关工作内容，分析可以推进的方向（总结见附件）
            - [ ] 【D】11月08日前，调研自动化安装部署工具的发展趋势
                - [ ] 【本日进展】，调研Helm的发展趋势和前景
            - [ ] 【D】11月09日前，评估通过Operators能否实现组件的扩容等高级问题。
                - [ ] 【本日进展】了解Operators相关内容，输出分析文档
                - [ ] 【本日进展】搭建OpenShift平台试用
            - [ ] ~~【D】11月09日前，调研云服务商Ali提供的大数据服务。~~
      - [ ] 【W】11月16日前，从安装、运维、API、选型等方面对大数据平台相关工作进行价值分析，输出调研文档
            - [ ] 【D】11月12日，调研大数据平台的如何进行故障恢复，我们当前做了哪些工作？未来可以做哪些工作？
                - [ ] 【本日进展】收集AIOps相关资料，查阅AIOps当前的故障恢复方面的内容。
            - [ ] 【D】11月13日，初步完成大数据平台相关的价值调研。
                - [ ] 【本日进展】完成初步的调研，并得出分析结论（具体见附件第六小节）。
            - [ ] 【D】11月14日，完成调研阶段性汇报
                - [ ] 【本日进展】完成阶段的汇报，后续从选型和故障恢复两个方面继续分析。
            - [ ] 【D】11月15日，盘点故障检查工具&效率提升工具
                - [ ] 【本日进展】调研Facebook，代码debug工具
                - [ ] 【本日进展】调研磁盘故障预测相关的研究成果
            - [ ] 【D】11月16日，盘点故障检查工具&效率提升工具
                - [ ] 【本日进展】调研时间序列检测算法库
                - [ ] 【本日进展】调研日志管理工具
        - [ ] 【W】11月23日前，总结平台组件选型、故障管理等方面的工作内容，调研能够优化这方面工作的开源组件
            - [ ] 【D】11月19日，总结平台组件选型的一般流程
                - [ ] 【本日进展】调研分布式链路监控工具
                - [ ] 【本日进展】总结选型工作，细化该工作流程。
            - [ ] 【D】11月20日，调研查找能够帮助选型的开源工具
            - [ ] 【D】11月21日，调研查找能够帮助选型的开源工具
            - [ ] 【D】11月22日，根据阶段进展待定
            - [ ] 【D】11月23日，根据阶段进展待定


### 【三级拆解】临时任务
- [ ] 【W】11月23日前，调研Operator Framework概念，分析Kafka、Spark的开源Operator包使用方式，输出使用文档
        - [ ] 【D】11月21日，调研Operator Framework概念，理解应用场景，以及工作原理
        - [ ] 【D】11月22日，使用开源Spark Operator
        - [ ] 【D】11月23日，使用开源Kafka Operator
  