# 【项目1】大数据平台

##【子项目】IBNS项目相关任务

### 【三级拆解】Spark集群模式Kubernetes部署，以及spark相关任务支撑保障
#### 【阶段目标】 Spark-Cluster 部署，App任务提交任务方案设计
- [ ] 【D】10月8日，Spark on glusterfs 以及 hadoop on glusterfs调研
    - [ ] 【本日进展】
        - hadoop/spark on glusterfs 插件调研。该插件可以是Hadoop/Spark直接读写数据到glusterfs。git上该插件已经3年没有更新，个人判断目前应该用不上这个插件。
        - Q4任务拆分
        - Spark Standalone jar包分发机制确认。Jar的分发路径为Client -> Driver -> worker。Driver到worker这步是自动完成的，但是Client到Driver这一步需要手工完成（或者将Jar放到HDFS、http服务器）。
- [ ] 【D】10月9日，Standalone模式下，设计Spark任务提交方式、业务jar包分发方式、业务Helm包打包方式。
    - [ ] 【本日进展】
        - 集群模式下的Checkpoint问题：可以确定Checkpoint目录必须是共享目录（HDFS/所有workder可以的目录）。官网没有叙述streaming任务必须配置checkpoint目录，但是博客的说法是DStream的有状态转换需要checkpoint（有状态转换算子包括：updateStatebyKey，window，特点是依赖之前的批次数据或者中间结果来计算当前批次的数据）。WIS业务代码中没有使用updateStatebyKey、window算子。但是Kafka依赖库中有使用到updateStatebyKey。（PS：咨询过玉良，没有给wo答复）
        - 集群模式下的Shuffle异常问题：表现为从本地Shuffle读Block时找不对应的Shuffle文件，但是该问题时有时无需要进一步观察。
~~- [ ] 【D】10月10日，Streaming 任务监控功能开发~~
- [ ] 【D】10月10日，Standalone模式下，设计Spark任务提交方式、业务jar包分发方式、业务Helm包打包方式。输出使用文档
    - [ ] 【本日进展】
        - spark集群模式使用文档，集群模式wis任务helm包修改（文档见附件）-- spark集群模式的helm包已经基本可用
- [ ] 【D】10月11日，任务监控功能整合Standalone镜像，调试测试
    - [ ] 【本日进展】
        - spark 流处理监控功能整合，实现python脚本从streaming页面抓取batches运行时间，通过k8s的健康检查判断是否需要重启流处理任务--- 脚本编码完成，自测试OK
- [ ] 【D】10月12日，spark2 集群环境整合python3，提供给行雄进程调试
    - [ ] 【本日进展】
        - 同步Spark2-Cluster给行雄使用，（工作包括：python3整合、helm包修改、文档修订、Spark Metrics指标接入）  ---- 完成
#### 【阶段目标】 Spark REST API接口调研
- [ ] 【D】10月15日，Spark jobservice 基本功能调研，以及安装使用
    - [ ] 【本日进展】
        - spark jobservice安装部署，使用文档简要整理。基本使用方式，接口功能已经摸清 --- 详情见附件
        - 考虑到jobservice功能比较全面，如果并发性的考量的话自研框架会有局限。所以计划任然以jobservice作为第一选择。
- [ ] ~~【D】10月16日，Spark jobservice 容器化方案确定~~ 【D】10月16日，jobservice开发接口熟悉，编写一个demo查询db，返回查询结果
    - [ ] 【本日进展】
        - 完成jobservice 两个demo编写，包括：一个字符统计，和mongodb查询
        - 和晓林安装拷机环境
- [ ] 【D】10月17日，Spark jobservice 容器化方案确定
    - [ ] 【本日进展】
        - 完成Spark jobservice容器化，输出Helm包。
        - 当前识别到JobService对共享存储有需要。JobService中的一些数据时存储存在文件中的，没有共享存储时pod退出后，需要重新上传jar包。
- [ ] 【D】10月18日，Spark jobservice使用文档，Demo整理
    - [ ] 【本日进展】
        - 完成Job Serverice 的使用说明文档（包括Helm、Demo、文档，已经可以交付使用）
- [ ] 【D】10月19日，~~实现一个spark driver内部的接口，使用户可以动态触发job~~ Spark 集群模式拷机环境部署
    - [ ] 【本日进展】
        - 部署spark cluster到拷机环境，配置wis集群版本，进行拷机（1000倍压力，提高spark任务资源后运行业务正常，但是磁盘io 100%）
        - 搭建glusterfs到拷机环境（输出一个一键部署脚本）
#### 【阶段目标】 Spark-Cluster稳定测试、glusterfs与HDFS选型对比
- [ ] 【D】10月22日，Spark-Cluster 稳定测试，协助AI任务性能问题定位
    - [ ]【本日进展】
        - Spark AI性能问题分析：编码测试DF、RDD读取MongoDB的性能，发现主要性能瓶颈不是mongodb，无论DF还是RDD 500w记录加载完成大概40s
        - Spark AI性能问题分析：翻译AI业务的Python为Scala，发现同样逻辑，scala的性能是python的2倍。
- [ ] 【D】10月23日，glusterfs特性熟悉，与HDFS进行比较（输出比较文档）
    - [ ]【本日进展】
        - IBNS共享存储需求场景分析，共享存储系统调研（当前IBNS的主要需求是：大量的小文件的读写，对可靠性、性能要求不高。但是比较遗憾的是包括：Ceph、Gluster、MooseFS内的分布文件系统，处理小文件性能不佳是通病！而HDFS本身是为高吞吐IO设计的，小文件处理能力是最差的！！ PS：个人认为WIS、IData业务都有在HDFS存储大量小文件的场景，这是一种设计缺陷，可以进行优化）
        - 应ION要求修改Spark基础镜像，安装GCC和指定的库
- [ ] 【D】10月24日，~~glusterfs 和 HDFS 环境下，Spark性能测试对比~~ glusterfs 架构特性调研
    - [ ] 【本日进展】
        - 整合History到Spark2的Helm包（日志目录使用Glusterfs存储）
        - 了解Gluterfs的Volume特性，查找关于Glusterfs底层架构FUSE的资料（PS：从Glusterfs的实现架构来看，该文件系统天生小文件处理能力不佳。创建过多的小文件，会使Glusterfs的性能相比裸盘下降80%之多。 附件文档中有详细说明）
- [ ] 【D】10月25日， glusterfs IO逻辑机梳理，HDFS和Glusterfs相关特性对比
    - [ ] 【本日进展】
        - glusterfs Translator逻辑梳理
        - 输出glusterfs与HDFS比较文档
- [ ] 【D】10月26日， IBNS问题支持，glusterfs HDFS对比，机房搬迁
    - [ ] 【本日进展】
        - 机房搬迁~~~！！！
        - IBNS spark任务问题定位，加载so库失败，原因是缺少环境变量LD_LIBRARY_PATH
        - HDFS Glusterfs 打分表（见附件）


- [ ] 【W】10月31日前，完成hdfs组件容器化实现方案及路径探索，并实现初步原形。

      - [ ] 【D】10月29日，~~hdfs组件容器化实现方案及路径探索(50%)~~ 机房服务器上线，k8s平台环境重装
        - [ ] 【本日进展】
                -  机房服务器上线，k8s平台环境重装
      - [ ] 【D】10月30日, hdfs组件容器化实现方案及路径探索(50%)
        - [ ] 【本日进展】
                - 调研HADOOP容器化方案，输出单节点/多节点初步方案（见附件）
      - [ ] 【D】11月01日，hdfs组件容器化实现方案及路径探索，初步列出可行的方案。
        - [ ] 【本日进展】
                - 排查IBNS任务问题 （具体见附件）
                - 调研 HADOOP 容器的HA方案，发现容器化实施时，存在以下难点：1、初次部署时，Namenode、Journalnode、ZKFC需要顺序执行初始化操作，需要额外开发脚本实现自动初始化；2、Namenode进行主备切换时，需要额外脚本防止脑裂；
                - 完成单节点的Hadoop版本。
      - [ ] 【D】11月02日，待定
      - [ ] 【D】11月03日，待定